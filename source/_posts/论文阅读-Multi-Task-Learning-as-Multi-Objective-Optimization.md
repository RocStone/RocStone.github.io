---
title: 【不完整】论文阅读 Multi-Task Learning as Multi-Objective Optimization
date: 2021-05-04 15:39:40
tags: Paper Reading
---

# Multi-Task Learning as Multi-Objective Optimization
作者： Ozan Sener, Vladlen Koltun from Intel Labs

在多任务学习中，多种任务被同时解决。**这些任务也共享了推导bias**。多任务学习从根本上来说是一个多目标问题，因为不同的任务可能是冲突的，必然会带来一个trade-off. 常见的做法是，通过优化一个间接的目标函数(proxy object)，来最小化所有任务的loss的加权和。
但这种方式仅仅在所有任务互相不竞争（compete）的情况才行，然而多数时候它们都是会互相竞争的。所以我们显式的把多任务学习变成多目标优化，总体的目标是找到柏拉图最优解（Pareto optimal solution）。为此，我们使用了基于梯度的多目标优化。这些算法并不能直接应用到大规模的学习学习问题中，因为它们在梯度规模和任务量上的伸缩性很差。因此，我们提出一个多目标loss的上界，然后证明最优化这个上界并且基于一些比较实际的假设，就能够达到柏拉图最优解。把方法用到数字分类，场景学习（包括semantic segmentation, instance segmentation和深度估计），多标签学习。

用我的话改写：
1. 多任务学习从根本上来说是多目标学习
2. 常见的多任务学习是最小化所有任务的loss加权和
3. 但是这种方式**有问题**：因为任务之间多数时候会互相竞争。
4. 解决思路：把多任务学习变成多目标优化（gradient-based multi-object optimization），然后找柏拉图最优解。
5. 具体方法：使用基于梯度的多目标优化。
6. 进一步的问题：这个方法难以解决任务量多、梯度规模高的情况。
7. 进一步的解决方法：推导证明出它的上界，通过最优化上界+一些比较实际的假设，来达到柏拉图最优解。

高度概括：
1. 提出问题：现有的proxy object不行
2. 提出方案：转变成多目标学习，用梯度优化来解
3. 提出进一步的问题：难以处理多目标、高维度的情况。
4. 提出进一步的方案：证明出上界，最小化其上界+一些假设，来达到柏拉图最优解。

基本概念介绍：
柏拉图最优，也叫帕累托最优。指在给定一些人和资源的情况下，无法提出一种新的方案，使得所有人的利益都不受损的情况下，让某一方利益更大化。

阅读前带着问题：
1. 论文如何论述现有的proxy object不行？用图？还是引用其他论文？
2. 论文如何解释转化成多目标优化就可以解决这个问题了？
3. 解释什么是基于梯度的多目标优化？具体是怎么做的？
4. 简单查看他的证明思路。
5. 看看他的实验大概怎么做的，setting是什么，数据集是什么


这是一篇组内分享的论文，我还没来得及往下看，宣讲者已经讲了，但是细节他没说到位。这也不是我的方向，所以我就做进一步的阅读了。

# 文摘：从原文摘出我觉得有趣的东西
1. Stein’s paradox： 要估计三个及以上高斯随机变量各自的u时，应该这些数据全部都用起来，而不是单独的去估计它们。[这个pdf给了一个完美的例子和解释](http://bayes-stat.github.io/download/stein.pdf)。
   - 我用人话来概括一下，如果有3个以上的运动员在打棒球，现在有了他们各自的击球结果记录。在估计他们各自的命中率时，不要直接求他们各自的极大似然估计，因为这样不准。（没错，即使这些运动员是相互独立的），但是他们就是不准。最好的办法是在估计任何一个人的命中率时，把其他人的击球结果记录也用起来。
   - 这个paradox真是太有意思了！

